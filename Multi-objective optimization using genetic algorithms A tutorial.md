# Multi-objective optimization using genetic algorithms: A tutorial

## 1.Introduction

本文的目的是介绍使用遗传算法 (GA) 的多目标优化方法的概述和教程。 对于多目标问题，目标通常是相互冲突的，从而阻止了每个目标的同时优化。 许多甚至大多数实际工程问题实际上都有多个目标，即最小化成本、最大化性能、最大化可靠性等。这些都是困难但现实的问题。  GA 是一种流行的元启发式算法，特别适合此类问题。 传统的遗传算法通过使用专门的适应度函数和引入促进解决方案多样性的方法来定制以适应多目标问题。

多目标优化有两种通用方法。 一种是将单独的目标函数组合成一个单一的复合函数，或者将除一个目标之外的所有目标移动到约束集。 在前一种情况下，可以通过效用理论、加权总和法等方法确定单个目标，但问题在于正确选择权重或效用函数来表征决策者的偏好。

在实践中，即使对于熟悉问题域的人，也很难准确地选择这些权重。 使这个缺点更加复杂的是，需要在目标之间进行缩放，权重的小扰动有时会导致完全不同的解决方案。 在后一种情况下，问题是要将目标移动到约束集，必须为这些先前的每个目标建立一个约束值。

这可能相当随意。 在这两种情况下，优化方法将返回单个解决方案，而不是一组可以进行权衡检查的解决方案。 出于这个原因，考虑到多个目标，决策者通常更喜欢一套好的解决方案。

第二种通用方法是确定整个帕累托最优解集或代表性子集。 帕累托最优集是一组相互之间非支配的解。 在从一种帕累托解决方案转移到另一种帕累托解决方案时，在一个或多个目标中总会有一定的牺牲，以在其他（多个）目标中获得一定的收益。 帕累托最优解集通常比单一解更受青睐，因为它们在考虑现实生活中的问题时很实用，因为决策者的最终解总是一种权衡。 帕累托最优集可以有不同的大小，但帕累托集的大小通常随着目标数量的增加而增加。

## 2.Multi-objective optimization formulation

考虑一个决策者，他希望优化 K 个目标，使得这些目标是不可公度的，并且决策者对彼此之间的目标没有明确的偏好。 不失一般性，所有目标都是最小化类型——最小化类型的目标可以通过乘以负数来转换为最大化类型。 一个具有 $K$​​ 个目标的最小化多目标决策问题定义如下： 给定解空间 $X$​​ 中的一个 $n$​​ 维决策变量向量 $x =\{x_1,...,x_n\} $​​，找到一个向量 $x^*$​ 来最小化给定的一组 $K$​ 目标函数 $z(x^*) = {z_1(x^*),...,z_K(x^*)}$​。 解空间 $X$​ 通常受到一系列约束的限制，例如 $g_j(x^*) =b_j\ for\ j= 1, ..., m$, 以及决策变量的边界。

在现实生活中的许多问题中，所考虑的目标相互冲突。 因此，针对单个目标优化 $x$ 通常会导致针对其他目标的不可接受的结果。 因此，同时优化每个目标函数的完美多目标解决方案几乎是不可能的。 多目标问题的合理解决方案是研究一组解决方案，每个解决方案都在可接受的水平上满足目标，而不受任何其他解决方案的支配。

如果所有目标函数都是为了最小化，则称一个可行解 $x$​​​​ 支配另一个可行解 $y (x >y)$​​​，当且仅当， $z_i(x)\le z_i(y)$​​​ ($i=1,..,K$​​) 以及 $z_j(  x)<z_j(y)$​ 用于至少一个目标函数 $j$​。 如果一个解不受解空间中任何其他解的支配，则称该解是帕累托最优的。 帕累托最优解不能在不恶化至少一个其他目标的情况下针对任何目标进行改进。 $X$​ 中所有可行的非支配解的集合称为帕累托最优集，对于给定的帕累托最优集，目标空间中对应的目标函数值称为帕累托前沿。 对于许多问题，帕累托最优解的数量是巨大的（可能是无限的）。

多目标优化算法的最终目标是确定帕累托最优集中的解。 然而，对于许多多目标问题，识别整个帕累托最优集实际上是不可能的，因为它的大小。 此外，对于许多问题，尤其是组合优化问题，解决方案最优性的证明在计算上是不可行的。 因此，多目标优化的一种实用方法是研究一组尽可能代表帕累托最优集的解决方案（最著名的帕累托集）。 考虑到这些问题，多目标优化方法应该实现以下三个相互矛盾的目标 [1]：

1. 已知最优的帕累托前沿应该尽可能接近真正的帕累托前沿。 理想情况下，最著名的帕累托集应该是帕累托最优集的子集。
  2. 最著名的帕累托集中的解决方案应该在帕累托前沿上均匀分布和多样化，以便为决策者提供权衡的真实画面。
  3. 最著名的帕累托前沿应该捕获帕累托前沿的整个频谱。 这需要在目标函数空间的极端研究解决方案。

对于给定的计算时间限制，第一个目标最好通过将搜索集中（加强）帕累托前沿的特定区域来实现。 相反，第二个目标要求搜索工作在帕累托前沿上均匀分布。 第三个目标旨在扩展两端的帕累托前沿，探索新的极端解决方案。

本文介绍了多目标遗传算法中使用的常用方法，以在解决多目标优化问题的同时实现这三个相互冲突的目标。

## 3.Genetic algorithms

GA 的概念是由 Holland 及其同事在 1960 年代和 1970 年代提出的 [2]。  GA 的灵感来自解释物种起源的进化论。 在自然界中，环境中的弱者和不适合的物种面临着自然选择的灭绝。 强者更有机会通过繁殖将基因传给后代。 从长远来看，基因中携带正确组合的物种在其种群中占据优势。 有时，在缓慢的进化过程中，基因可能会发生随机变化。

如果这些变化在生存挑战中提供了额外的优势，新物种就会从旧物种进化而来。 自然选择消除了不成功的变化。在 GA 术语中，解向量 $x\in X$ 称为个体或染色体。 染色体由称为基因的离散单元组成。 每个基因控制染色体的一个或多个特征。 在 Holland 最初的 GA 实现中，基因被假定为二进制数字。 在后来的实施中，引入了更多不同的基因类型。 通常，染色体对应于解空间中的唯一解 $x$。 这需要解空间和染色体之间的映射机制。 这种映射称为编码。

事实上，GA 致力于解决问题的编码，而不是解决问题本身。遗传算法处理一组染色体，称为种群。 总体通常是随机初始化的。随着搜索的发展，种群包括更合适的解决方案和更合适的解决方案，并最终收敛，这意味着它由单一解决方案主导。  Holland 还提出了收敛性证明（模式定理）到全局最优解，其中染色体是二元向量。

GA 使用两个算子从现有的解决方案中生成新的解决方案：交叉和变异。 交叉算子是遗传算法最重要的算子。 在交叉中，通常称为父母的两条染色体结合在一起形成新的染色体，称为后代。 亲本是从种群中现有的染色体中选择的，优先考虑适合度，从而期望后代继承使亲本更适合的良好基因。 通过迭代应用交叉算子，好的染色体的基因有望在群体中更频繁地出现，最终导致收敛到一个整体好的解决方案

变异算子将随机变化引入到染色体的特征中。 突变通常应用于基因水平。 在典型的 GA 实现中，突变率（改变基因特性的概率）非常小，取决于染色体的长度。 因此，突变产生的新染色体与原来的染色体不会有太大的不同。 突变在遗传算法中起着至关重要的作用。 如前所述，交叉使种群中的染色体相似，从而导致种群收敛。 突变将遗传多样性重新引入种群中，并帮助搜索逃离局部最优。   繁殖涉及为下一代选择染色体。 在最一般的情况下，个体的适应度决定了其为下一代生存的概率。 根据适应度值的使用方式，GA 中有不同的选择程序。   比例选择、排名和锦标赛选择是最流行的选择程序。 通用遗传算法[3]的过程如下：

第 1 步：设置 $t =1$。随机生成 $N$ 个解以形成第一个种群 $P_1$。 评估 $P_1$ 中解的适合度。

第 2 步：交叉：按如下方式生成后代种群 $Q_t$： 

2.1． 根据适应度值从 $P_t$ 中选择两个解 $x$ 和 $y$。

2.2. 使用交叉运算符，生成后代并将它们添加到 $Q_t$。

第 3 步：变异：用预定义的变异率变异每个解 $x\in Q_t$。

第 4 步：适应度分配：根据每个解 $x\in Q_t$ 的目标函数值和不可行性评估并为其分配适应度值。

第五步：选择：根据适合度从 $Q_t$​ 中选择 $N$​ 个解，复制到 $P_{t+1}$。

Step 6：如果满足停止条件，则终止搜索返回当前种群，否则设t ¼ t+1 转Step 2。

## 4.Multi-objective GA

作为一种基于群体的方法，遗传算法非常适合解决多目标优化问题。 可以修改通用的单目标 GA 以在一次运行中找到一组多个非支配解决方案。  GA 同时搜索解空间的不同区域的能力使得为具有非凸、不连续和多模态解空间的难题找到一组不同的解决方案成为可能。  GA 的交叉算子可以利用针对不同目标的良好解的结构，在帕累托前沿的未探索部分创建新的非支配解。 此外，大多数多目标 GA 不需要用户对目标进行优先级排序、缩放或权衡。 因此，遗传算法一直是多目标设计和优化问题最流行的启发式方法。 琼斯等人。  [4] 报告说，90% 的多目标优化方法旨在逼近潜在问题的真实帕累托前沿。 其中大部分使用了元启发式技术，所有元启发式方法中有 70% 基于进化方法

第一个多目标 GA，称为向量评估 GA（或 VEGA），由 Schaffer [5] 提出。 随后，开发了几种多目标进化算法，包括多目标遗传算法（MOGA）[6]、Niched Pareto遗传算法（NPGA）[7]、基于权重的遗传算法（WBGA）[8]、随机加权遗传算法 （RWGA）[9]，非支配排序遗传算法（NSGA）[10]，强度帕累托进化算法（SPEA）[11]，改进的SPEA（SPEA2）[12]，帕累托存档进化策略（PAES）[13]， 基于帕累托包络的选择算法 (PESA) [14]、进化多目标优化中的基于区域的选择 (PESA-II) [15]、快速非支配排序遗传算法 (NSGA-II) [16]、多目标进化算法 (  MEA) [17]、Micro-GA [18]、基于秩密度的遗传算法 (RDGA) [19] 和动态多目标进化算法 (DMOEA) [20]。 请注意，尽管文献中多目标 GA 有许多变体，但这些引用的 GA 是众所周知且可靠的算法，已在许多应用中使用，并且在多项比较研究中测试了它们的性能。

几篇关于进化多目标优化的调查论文 [1,11,21-27] 已经发表。  Coello 在他的网站 [28] 中列出了 2000 多篇参考文献。 通常，多目标遗传算法因其适应度分配程序、精英主义或多样化方法而异。 在表 1 中，给出了众所周知的多目标的重点及其优缺点。 大多数关于多目标进化方法的调查论文都介绍和比较了不同的算法。 本文采用不同的课程，重点关注设计多目标 GA 时的重要问题，并描述了多目标 GA 中用于实现多目标优化中的三个目标的常用技术。  Zitzler 等人的调查论文也采用了这种方法。  [1]。 然而，本文的讨论旨在向没有多目标 GA 背景的研究人员和从业者介绍多目标 GA 的组成部分。 同样重要的是要注意，尽管上面引用的几种最先进的算法存在，但许多将多目标 GA 应用于其问题的研究人员更喜欢通过适应各种多目标 GA 的策略来设计自己的定制算法 . 这一观察结果是引入多目标 GA 组件而不是专注于几种算法的另一个动机。 但是，还提供了一些著名的多目标 GA 的伪代码，以演示如何将这些过程合并到多目标 GA 中。

![image-20210811074643571](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20210811074643571.png)

## 5. Design issues and components of multi-objective GA

### 5.1. Fitness functions

#### 5.1.1. Weighted sum approaches

解决多目标优化问题的经典方法是为每个归一化目标函数 $z_i'(x)$ 分配权重 $w_i$，以便将问题转换为具有标量目标函数的单目标问题，如下所示：
$$
min\ z=w_1z_1'(x)+w_2z_2'(x)+...+w_kz_k'(x)\ ——(1)
$$
其中 $z_ i'(x)$​ 是归一化的目标函数 $z_i(x)$​ 和 $\Sigma w_i = 1$​。这种方法被称为先验方法，因为期望用户提供权重。对于给定的权重向量 $w = \{w_1, w_2,...,w_k\}$​ 使用目标函数 (1) 解决问题会产生一个解决方案，如果需要多个解决方案，则必须使用不同的权重组合多次解决该问题。 这种方法的主要困难是为每次运行选择一个权重向量。 自动化这个过程；  Hajela 和 Lin [8] 在 WBGA-MO 中提出了 WBGA for multi-objective optimization (WBGA-MO)，种群中的每个解 $x_i$​ 在计算中使用不同的权重向量 $w_i = \{w_1, w_2,...,w_k\}$​ 求和的目标函数 (1)。 权重向量 $w_i$ 嵌入在解 $x_i$ 的染色体中。 因此，可以在一次运行中同时搜索多个解决方案。 此外，可以调整权重向量以促进种群的多样性。

其他研究人员 [9,31] 提出了基于多个目标函数的加权和的 MOGA，其中在每一代的选择阶段为每个解决方案 $x_i$ 随机生成归一化的权重向量 $w_i$。这种方法旨在在不使用额外参数的情况下在一次运行中规定多个搜索方向。 使用随机权重的 RWGA 的一般程序如下[31]：

程序 RWGA：

$E$ = 外部存档，用于存储迄今为止在搜索过程中找到的非支配解； 

$n_E$ =每一代中从 E 迁移到 P 中的精英解数量

步骤 1：生成随机种群

步骤 2：通过执行以下步骤为每个解 $x\in P_t$ 分配一个适应度值

步骤 2.1：为每个目标 $k(k=1,...,K)$ 生成一个随机数 $u_k\in[0,1]$。

步骤 2.2：计算每个目标 $k$ 的随机权重为 $w_k=(1/u_k)\Sigma_{i=1}^Ku_i$。

步骤 2.3：计算解的适应度为 $f(x)=\Sigma_{k=1}^Kw_kz_k(x)$。

步骤 3：计算每个解 $x\in P_t$ 的选择概率如下： $p(x) = (f(x)-f^{min})^{-1}\Sigma_{y\in P_t}(f(y)-f^{min})$​ 其中 $f^{min} = min\{f (x)|x \in P_t\}$。

第 4 步：使用第 3 步中计算的选择概率选择父母。对选定的父母对应用交叉以创建 N 个后代。使用预定义的突变率变异后代。 将所有后代复制到 $P_{t+1}$。如有必要，更新 E。

步骤 5：从 $P_{t+1}$ 中随机去除 $n_E$ 个解，并将 E 到 Pt+1 中相同数量的解加入。

Step 6：若不满足停止条件，则设t ¼ t þ 1，转Step 2，否则返回E。

加权和方法的主要优点是简单的实现。 由于在适应度分配中使用单个目标，因此可以使用单个目标 GA 进行最少的修改。 此外，这种方法在计算上是高效的。 这种方法的主要缺点是，当真正的帕累托前沿是非凸的时，并不是所有的帕累托最优解都可以研究。 因此，基于加权和方法的多目标遗传算法难以找到均匀分布在非凸折衷面上的解[1]。

#### 5.1.2. Altering objective functions

如前所述，VEGA [5] 是第一个用于通过一组非支配解来逼近帕累托最优集的遗传算法。 在 VEGA 中，种群 $P_t$​ 被随机分成 $K$​ 个大小相等的子种群；  $P_1，P_2，...，P_K$。 然后，基于目标函数 $z_i$ 为子群 $P_i$ 中的每个解决方案分配一个适应度值。 使用交叉和突变的比例选择从这些亚群中选择解决方案。 以与单个目标 GA 相同的方式对新种群执行交叉和变异。

$N_S$​ = 亚群大小 $(N_S = N/K)$

步骤 1：从随机初始种群 $P_0$​ 开始。 设置 $t = 0$。

步骤 2：如果满足停止条件，则返回 $P_t$。

步骤 3：随机排序种群 $P_t$。

步骤 4：对于每个目标 $k$​，$k = 1,...,K$，执行以下步骤：

步骤 4.1：对于 $i = 1 + (k-1)N_S,  .  .  .  ,kN_S$，将适应度值 $f(x_i) = z_k(x_i)$ 分配给排序种群中的第 $i$ 个解

步骤 4.2：根据步骤 4.1 中分配的适应度值，在排序种群的第 $(1+(k -1)N_S)$​ 个和第 ($kN_S$) 个解之间选择 $N_S$ 个解，以创建子种群 $P_k$​。

步骤 5：合并所有子种群 $P_1,...,P_k$​ 并对合并的种群应用交叉和变异以创建大小为 $N$​ 的 $P_{t+1}$​。设置 $t = t + 1$，转到步骤 2

与 VEGA 类似的方法是仅使用单个目标函数，该目标函数每次在选择阶段随机确定 [32]。 交替目标方法的主要优点是易于实现并且在计算上与单目标 GA 一样有效。 事实上，这种方法是单目标遗传算法的直接扩展，用于解决多目标问题。 目标切换的主要缺点是总体趋向于收敛到在一个目标上更好但在其他目标上差的解决方案。

#### 5.1.3. Pareto-ranking approaches

帕累托排序方法明确地利用帕累托优势的概念来评估适应度或为解决方案分配选择概率。 根据优势规则对种群进行排名，然后根据其在种群中的排名，而不是其实际目标函数值，为每个解决方案分配一个适应度值。 请注意，这里假设所有目标都被最小化。 因此，在以下讨论中，较低的等级对应于更好的解决方案。

第一个帕累托排序技术是由 Goldberg [3] 提出的，如下所示：

步骤 1：设置 $i = 1$​ 和 $TP = P$。

步骤 2：识别 $TP$ 中的非支配解并将它们分配给 $F_i$。

第 3 步：设置 $TP = TPF_i$​。 如果 $TP =\varnothing$ 转到步骤 4，否则设置 $i = i + 1$ 并转到步骤 2。

步骤 4：对于第 t 代的每个解 $x\in P$​​，分配排名  $r_1(x,t)=i$​ 如果 $x\in F_i$。

在上面的过程中，$F_1, F_2,...$ 被称为非支配前沿，$F_1$ 是种群 $P$ 的帕累托前沿。 NSGA [10] 也使用类似于上面给出的算法将种群分类为非支配前沿。 然后使用适应度共享函数为每个前沿分配一个虚拟适应度值，使得分配给 $F_i$ 的最差适应度值优于分配给 $F_{i+1}$ 的最佳适应度值。  NSGA-II [16] 是一种更有效的算法，称为快速非支配排序算法，被开发用于形成非支配前沿。  Fonseca 和 Fleming [6] 使用的排名分配方法与基于非支配前沿的排名略有不同，如下所示：
$$
r_2(x,t)=1+nq(x,t)
$$
其中 $nq(x,t)$ 是在第 $t$ 代支配解 $x$​ 的解的数量。 这种排序方法惩罚位于目标函数空间区域中的解，这些区域由帕累托前沿的人口稠密部分主导（覆盖）。 例如，在图 1b 中，解决方案 $i$ 由解决方案 $c$、$d$ 和 $e$ 主导。 因此，尽管它与仅由单个解支配的解 $f$、$g$ 和 $h$ 处于同一前沿，但它被指定为 4。

SPEA [11] 使用排序程序为目标空间中代表性不足的区域的非支配解决方案分配更好的适应度值。 在 SPEA 中，一个固定大小的外部列表 E 存储了迄今为止在搜索过程中研究过的非支配解。 对于每个解 $y\in E$，强度值定义为

<img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20210811115247703.png" alt="image-20210811115247703" style="zoom:67%;" />

其中 $nq (y, t)$​​​ 是 $y$​​ 在 $P$​​ 中占主导地位的解数。解 $y\in E $​ 的等级 $r(y,t)$ 被指定为 $r_3(y,t)=s(y,t) $;  解 $x\in  P$ 的等级计算为
$$
r_3(x,t)=1+\Sigma_{y\in E,y>x}s(y,t)
$$
图 1c 说明了 SPEA 排名方法的一个例子。 在前两种方法中，所有非支配解都被指定为 1。然而，这种方法比其他非支配解更偏爱解 a（图中），因为它覆盖了目标函数空间中最少的解。 因此，鼓励广泛、均匀分布的非支配解决方案集。累积排名密度策略 [19] 还旨在惩罚由于过度代表而导致的人口冗余。

这种排名方法被给出为

<img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20210811133550923.png" alt="image-20210811133550923" style="zoom: 67%;" />

要计算解 $x$​ 的等级，必须首先计算支配该解的解的等级。图 1d 显示了这种排序方法的一个例子（基于 $r_2$​）。 使用排序方法 $r_4$​，解决方案 $i、l$ 和 $n$ 在同一非支配前沿的排名高于其对应项，因为覆盖它们的权衡表面部分被三个附近的解决方案 $c$、$d$ 和 $e$ 挤满。

尽管本节中描述的一些排序方法可以直接用于为单个解分配适应度值，但它们通常与各种适应度共享技术相结合，以实现多目标优化中的第二个目标，找到多样化且一致的帕累托前沿

### 5.2. Diversity: fitness assignment, fitness sharing, and niching

保持多样化的种群是多目标 GA 中的一个重要考虑因素，以获得在帕累托前沿上均匀分布的解决方案。 如果不采取预防措施，在多目标遗传算法中，种群往往形成相对较少的集群。 这种现象称为遗传漂变，并且已经设计了以下几种方法来防止遗传漂变。

#### 5.2.1. Fitness sharing

适应度共享通过人为地降低人口稠密地区解决方案的适应度来鼓励在帕累托前沿的未探索部分进行搜索。 为了实现这一目标，确定了人口稠密的区域，并使用惩罚方法来惩罚位于这些区域的解决方案。

适应度共享的想法首先由 Goldberg 和 Richardson [33] 在研究多模态函数的多个局部最优值时提出。  Fonseca 和 Fleming [6] 使用这个想法来惩罚具有相同等级的聚类解决方案，如下所示：

步骤 1：计算 0 和 1 之间归一化目标空间中每个解对 x 和 y 之间的欧几里德距离为(3)

<img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20210811133848948.png" alt="image-20210811133848948" style="zoom:50%;" />

其中 $z^{max} _k$​​ 和 $z^{min}_ k$​ 分别是到目前为止在搜索过程中观察到的目标函数 $z_k()$ 的最大值和最小值。

第 2 步：根据这些距离，计算每个解决方案 $x\in P$​ 的利基数量(4)
$$
nc(x,t)=\Sigma_{y\in P,r(y,t)=r(x,t)}max\{\frac{\sigma_{share-dz(x,y)}}{\sigma_{share}},0\}
$$
其中 $\sigma_{share}$ 是利基规模。

Step 3：计算 niche count后，对每个解的适应度进行如下调整：
$$
f'(x,t)=\frac{f(x,t)}{nc(x,t)}
$$
在上面的过程中，$\sigma _{share}$ 定义了目标空间中的解决方案的邻域（图 1a）。 同一邻域的解决方案有助于彼此的利基数量。 因此，拥挤邻域中的解决方案将具有更高的利基数量，从而降低选择该解决方案作为父解决方案的可能性。 因此，生态位限制了目标函数空间的一个特定邻域中解决方案的扩散。

另一种选择是使用决策变量空间中两个解 $x$ 和 $y$ 之间的距离，定义为(5)
$$
dx(x,y)=\sqrt{\frac1M\Sigma_{i=1}^M(x_i-y_i)^2}
$$
在计算利基数量时。 等式 (5) 是衡量两个解决方案之间结构差异的指标。 两个解在目标函数空间中可能非常接近，但它们具有非常不同的结构特征。 因此，基于目标函数空间的适应度共享可能会降低决策变量空间的多样性。 然而，Deb 和 Goldberg [34] 报告说，目标函数空间中的适应度共享通常比基于决策变量空间的适应度共享表现更好。

基于利基计数的适合度共享的缺点之一是用户必须选择一个新的参数 $\sigma_{share}$。 为了解决这个问题，Deb 和 Goldberg [34] 以及 Fonseca 和 Fleming [6] 开发了系统方法来估计和动态更新 $\sigma_{share}$​​。生态位的另一个缺点是计算生态位计数的计算工作量。 然而，健身共享的好处通常超过额外计算工作的成本。

Miller 和 Shaw [35] 提出了一种动态利基共享方法来提高计算利基计数的有效性。MOGA [6] 是第一个明确使用基于 Pareto 的排名和 Niching 技术的多目标 GA，以鼓励搜索真正的 Pareto 前沿，同时保持种群的多样性。

因此，这是一个很好的例子来演示如何将基于帕累托的排序和适应度共享集成到多目标 GA 中。  MOGA 的程序如下：

Procedure MOGA:

步骤 1：从随机初始种群 $P_0$​ 开始。 设置 $t = 0$。

步骤 2：如果满足停止条件，则返回 $P_t$。

步骤 3：按如下方式评估总体的适应度： 

步骤 3.1：使用等式(2)中给出的排名方案为每个解 $x\in P_t$ 分配排名 $r(x,t)$。  (2).
步骤 3.2：根据解决方案的等级为每个解决方案分配适应度值，如下 [36]：
$$
f(x,t)=N-\Sigma_{k=1}^{r(x,t)-1}n_k-.5\times (n_{r(x,t)}-1)
$$
步骤3.3：计算生态位计数 $nc(x,t)$​​；使用公式（4）计算每个解 $x\in P_t$​ 的。
步骤3.4：计算每个 解 $x\in P_t$ 的共享适应度值，如下所示：
$$
f'(x,t)=f(x,t)/nc(x,t)
$$
步骤3.5：通过使用共享的适应度值来规范化适应度值 
$$
f''(x,t)=\frac{f'(x,t)n_{n(x,t)}}{\Sigma_{{y\in P_t}}f'(x,t)}f(x,t)
$$
步骤4：使用基于 $f ''$​ 的随机选择方法为交配池选择亲本。在交配池上应用交叉和变异，直到大小为 $N$​ 的后代群体 $Q_t$​ 填满。设置 $P_{t+1}=Q_t$。

步骤5：设 $t=t+1$，转至步骤2。

在SPEA2[12]中，密度度量用于区分具有相同等级的解，其中解的密度定义为到目标函数空间中第 $k$ 个最近邻居的距离的倒数。解的密度与其生态位计数相似。但是，为参数 $k$ 选择一个值比为 $\sigma_{share}$ 选择一个值更简单。

#### 5.2.2. Crowding distance

拥挤距离方法的目的是在不使用适应度共享参数的情况下，沿着已知最优的帕累托前沿获得解的均匀分布。例如，NSGA-II[16]使用拥挤距离法，如下所示（图2b）：

步骤1：对种群进行排序，并确定非支配锋 $F_1、F_2、...、F_R$。对于每个锋 $j =1、...、R$，重复步骤2和3。

步骤2：对于每个目标函数 $k$​​​，按升序对 $F_j$​​​ 中的解进行排序。设 $l= |F_j|$​​ 和 $x_{\{i,k\}}$ ​ 表示排序列表中关于目标函数 $k$ 的第 $i$ 个解。分配cdkðx½1；k222;¼1和cdkðx½l；kÞ¼1，对于i¼2，y，l1赋值



附注：

## A FAST ELITIST MULTIOBJECTIVE GENETIC ALGORITHM: NSGA-II(非支配排序遗传算法2)

### Multi-Objective Optimization Using NSGA-IIHM: NSGA-II

NSGA（[5]）是一种流行的基于非支配的多目标优化遗传算法。这是一种非常直观的算法，但由于其计算复杂性、缺乏精英性以及为共享参数 $\sigma_{share}$ 选择最佳参数值而受到普遍批评。开发了一个改进版NSGAII（[3]），它具有更好的排序算法，融合了精英主义，无需事先选择共享参数。本文详细讨论了NSGA-II。

### General Description of NSGA-II

种群像往常一样初始化。初始化中的种群后，基于帕累托最优对种群中的个体进行排序，位于帕累托前沿的个体构成第一个集合，他们不受任何的其他解（也就是个体）支配，它们被排序为”1“；第二个集合则是仅被第一个集合中的解个体支配的个体的集合，依次类推。每个集合中的每个个体都被分配了等级（“能力”）值或基于他们所属的前线。第一个集合中的的个体被赋予“能力”值1，第二个集合中的个体被赋予“能力”值2，依此类推。

除了通过适合度值来对个体进行排序外，还为每个个体计算了一个称为拥挤距离的新参数。拥挤距离是衡量一个解与其在解空间中的邻域解的密度距的一个指标。较大的平均拥挤距离（换言之，解个体在空间中分布的更为广泛）将使种群具有更好的多样性。

亲本是通过基于排名和拥挤距离的二元锦标赛选择从人群中选出的。如果一个个体的排名小于另一个（帕累托更优的），或者如果拥挤距离大于另一个（更具有多样性的），则选择该个体。所选群体通过交叉和变异算子生成后代，这将在后面的章节中详细讨论。

接着将产生的后代与亲本一起再次根据帕累托最优排序，并且仅选择最佳的 $N$ 个个体，其中 $N$ 是第一次生成的种群大小。选择基于排名和最后一个集合（换言之，他们是排名最低的解）上各个解个体之间的拥挤距离

### Detailed Description of NSGA-II

#### 3.1. Population Initialization.

根据问题范围和约束（如果有）初始化构建种群。

#### 3.2. Non-Dominated sortization

初始化的群体是基于非支配进行排序的。下面分别描述了快速排序算法[3]

对于主要种群 $P$ 中的每个个体 $p$，请执行以下操作

- 初始化 $S_p=\empty$；。这个集合将包含所有被个体 $p$ 支配的个体。

- 初始化 $n_p=0$。这是支配个体 $p$ 的个体数。

- 对于 $P$ 中的每个个体 $q$

​          ·如果 $p$​ 支配 $q$​，则将 $q$​ 添加到设定的 $S_p$​ 中，即 $S_p=S_p\cup {q}$

​           否则，如果 $q$​ 支配 $p$​，则增加 $p$​ 的支配计数器，即 $n_p=n_p+1$

如果 $n_p=0$​​，即没有个体支配 $p$​​，则 $p$​​ 属于第一个集合；并且将个体 $p$​​ 的排名设置为一，即 $p_{rank}$​​ $=1$​。通过将 $p$​ 添加到第一集合，即 $F_1=F_1\cup {p}$​ 来更新第一集合

-这是对主要种群 $P$ 中的所有个体进行的。

-将集合计数器初始化为 1，$i=1$

-在第 $i$​ 个集合为非空时执行以下操作，即 $F_i \neq\empty$；

​          $Q=\empty$​，用于存储第$(i+1)^{th}$ 个集合的个体的集合。

​          for 每个位于集合 $F_i$ 中的个体 $p$

​                  for 每个位于集合 $S_p$ 中的个体 $q$ （ $S_p $ 是被解个体 $p$​ 支配的个体的集合）

​                            $n_q=n_q-1$ 在该次循环中，减少支配个体 $q$​ 的个体数量 1，即在接下来的过程中忽略上一个集合中的个体

​                            如果在减少以后， $n_q=0$​​​，那么在随后的集合中必然不会存在其余个体支配个体 $q$​​ 。因此，记 $q_{rank}=i+ 1$​ ，更新集合 $Q$ 中的元素（解个体），即 $Q=Q\cup q$                                                                                                            

接着将集合计数器增加1，并将集合 $Q$ 取代 $F_i$ 进入下一个循环，以寻找第 $i+2$ 个集合。

该算法优于原始NSGA（[5]），因为它利用了关于个体支配集（$S_p$）和支配个体的个体数（$n_p$）的信息。

#### 3.3. Crowding Distance.

一旦非支配排序完成，将分配拥挤距离。由于个体是根据等级和拥挤距离选择的，因此群体中的所有个体都被分配了一个拥挤距离值。 拥挤距离仅是对于同意集合中的个体而言的，比较不同集合中的两个个体之间的拥挤距离意义不大。拥挤距离的计算如下所示

对于每个集合 $F_i$，$n$ 记为个体数。

​           将所有个体的距离初始化为零，即 $F_i（d_j）=0$，

​           其中 $j$​ 对应于集合 $F_i$​ 中的第 $j$ 个个体。

​           对于每个目标函数 $m$

​                      根据目标 $m$​​​ 对 $F_i$​​​ 中的个体进行排序，即 $I=sort(F_i,m)$​​ 。(注：在这里，我们仅选取了一个目标函数，因此此处其实是一个循环，排序指的是我们在这个集合中，对于每个解个体计算对应于该目标函数的值，并进行排序)

​                     在该集合中取出使目标函数最大和最小的两个个体，将其拥挤距离定义为无穷大，即 $I(d_1)=\infin$和 $I(d_n)=\infin$​

​                     for $k=2$​(排序中的第二个个体) to $(n-1)$(排序中的倒数第二个个体)

​                                    $I(d_k)=I(d_k)+\frac{I(k+1).m-I(k-1).m}{f_m^{max}-f_m^{min}}$​​ (注：分子指的是集合中前一个个体和后一个个体值的差，分母中使用最大值和最小值进行了归一化）​

​                                    $I(k).m$ 是 I 中第 $k$ 个个体的第 $m$ 个目标函数的值

拥挤距离背后的基本思想是根据 $m$​ 维超空间中的 $m$​ 个目标，计算前方每个个体之间的欧几里德距离。边界中的个体始终处于选中状态，因为它们具有最近的距离分配。

#### 3.4. Selection.

一旦根据非支配性对个体进行排序并分配了拥挤距离，就会使用拥挤比较运算符 ($\prec_n$) 进行选择。 比较是基于以下依据进行的

(1) 非支配等级 $p_{rank}$，在集合 $F_i$ 中的个体排名为 $i$。

(2) 拥挤距离 $F_i(d_j)$

$ p \prec_n q$ 

----如果  $p_{rank}$​ $< q_{rank}$ 

----或者如果 $p$ 和 $q$ 在同一个集合 $F_i$ ，应当有 $F_i(d_p)>F_i(d_q)$ ，即拥挤距离更大

我们在二元锦标赛中对每次参赛的两个个体使用拥挤比较算子，选择等级较低（或者等级相同但拥挤距离大的）个体。

#### 3.5. Genetic Operators.

实编码 GA 使用模拟二进制交叉 (SBX) [2]、[1] 算子进行交叉和多项式变异 [2]、[4]。

##### 3.5.1. Simulated Binary Crossover.

模拟二进制二元交叉模拟自然界中观察到的二元交叉，如下所示。

$$
c_{1,k}=\frac12[(1-\beta_k)p_{1,k}+(1+\beta_k)p_{2,k}]
$$

$$
c_{2,k}=\frac12[(1+\beta_k)p_{1,k}+(1-\beta_k)p_{2,k}]
$$

其中 $c_{i,k}$ 是具有第 $k$ 个分量的第 $i$ 个子节点，$p_{i,k}$ 是选定的亲本（$i=1,2$ ）中对应第 $k$ 个目标函数的自变量（采用实数编码），而 $\beta_k (\ge0)$ 是来自具有密度的随机数生成的样本

<img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20210813210115918.png" alt="image-20210813210115918" style="zoom:67%;" />

这种分布可以从 (0; 1) 之间均匀采样的随机数 u 中获得。  ´c 是 crossover3 的分布指数。 那是

3.6. 重组和选择。后代种群与当前世代种群相结合，进行选择以设定下一代个体。 由于所有先前和当前的最佳个体都添加到种群中，因此确保了精英主义。 人口现在根据非统治进行排序。 新一代由每个战线随后填充，直到种群规模超过当前种群规模。 如果通过将 Fj 前面的所有个体相加，种群超过 N，则 Fj 前面的个体将根据其拥挤距离按降序选择，直到种群大小为 N。
   因此，重复该过程以生成后续世代。

## 二进制交叉

交叉算子被认为是作为优化工具的遗传算法 (GA) 工作中的主要搜索算子 (Goldberg, 1989)。 交叉算子的目的有两个。 必须彻底搜索表示问题变量的初始随机字符串，以创建好的字符串。 此后。 这些字段的大部分必须组合在一起以形成更好的字段。  GA 文献中存在许多交叉算子：然而，实现上述两个方面的搜索能力因一个交叉而异。  G As 的成功运行还取决于用于表示问题变量的编码机制（Kargupta、Deb 和 Goldberg，1992；Radcliff

1993）。 除非对好的构建块进行紧密编码，否则交叉算子无法将这些构建块组合在一起（Goldberg、Korb 和 Deb，1989）。 这种编码交叉交互对于 GA 的成功工作很重要。 二进制编码的 GA 在具有离散搜索空间的问题中的成功很大程度上是由于仔细选择了编码和交叉算子，它们在连续几代传播有用的构建块时相互补充。 问题变量编码紧密或松散的问题在很大程度上被称为链接问题，最近通过使用杂乱遗传算法（Goldberg, Korb, Deb, 1989; Goldberg, et. al, 1993）解决了二进制编码的 GAs  . 然而，在实数编码的 GA 中，直接使用变量。 因此，构成变量的位的紧编码或松编码不会出现，但不同变量的紧编码或松编码仍然存在。 是否真的存在一个实数编码的 Ga 来解决这个连锁问题是一个有趣的进一步研究。 然而，在本文中，我们认识到在 GA 的成功工作中多变量问题所固有的编码这一方面的重要性，但我们没有解决这个问题。 相反，我们设计了一个实数编码的交叉算子，它解决了二进制编码 GA 在处理具有连续搜索空间的问题时固有的一些其他困难

在使用二进制编码的 GA 解决具有连续搜索空间的问题时，通常选择二进制字符串来编码问题变量。 当二进制（离散）编码用于连续搜索空间时，会出现许多困难。 一个困难是与某些字符串相关的汉明悬崖，从中过渡到相邻解（在真实空间中）需要更改许多位。 二进制编码中的汉明悬崖会导致人为阻碍在连续搜索空间中逐步搜索。 另一个困难是无法在最优解中实现任意精度。 在二进制编码的 Gas 中，必须先验地选择字符串长度，以使 GA 能够在解决方案中达到一定的精度。 所需的精度越高，字符串长度就越大。 对于大字符串，种群大小要求也很大（Goldberg、Deb 和 Clark，1992），从而增加了算法的计算复杂度。 由于使用固定的映射编码来对变量进行编码，因此变量边界必须使它们包含最佳变量值。 由于在许多问题中，信息通常不是先验已知的，这可能会给在这些问题中使用二进制编码的 GA 带来一些困难。 此外，仔细考虑二进制字符串中的模式处理表明，在大多数具有连续搜索空间的问题中，并非所有 Holland 模式都同等重要。 对于一个连续的搜索空间，有意义的模式是那些代表搜索空间的连续区域的模式。 例如，schema($**** 1$​) 表示离散化搜索空间中的每隔一个点 虽然这个 schema 可能在某些周期性或振荡函数中有用，但 schema$(1 ****$ 表示一个更有意义的模式表示 大多数问题中搜索空间的右半部分。因此，需要重新设计二进制编码中使用的交叉算子，以增加与连续相关的更有意义的模式的传播

然而，由于二进制 GAs 在离散搜索空间问题中的成功以及意识到需要一个有效的实数编码的 GA 来消除连续搜索空间问题中二进制编码的 GAs 的上述困难，我们设计了一个实数编码的 交叉算子，简单地模拟二元交叉算子，但不使用变量编码。 为了实现这一点，我们根据从任意两个给定父字符串创建的任意子字符串的概率分布来定义交叉算子的搜索能力。首先计算单点交叉算子的搜索能力。 后来，模拟二进制交叉（SBX）被开发成具有类似于单点交叉的搜索能力。  SBX 实数编码 GAs 和单点交叉二进制编码 GAs 实现的区别在于，在前一种方法中，消除了变量的编码，并根据概率分布创建了一个子串，该概率分布取决于 父字符串的位置。 

尽管文献中存在许多其他实数编码的 GA（Eshelman 和 Scher，1993；Wright，1991），但这些交叉算子的搜索能力（如论文中所定义的）是不够的。 其中，Eshelman 和Schaer 的研究特别重要，因为他们引入了与连续搜索空间相关的模式（他们称之为区间模式）的概念。 这里可以提到，区间图式在概念上类似于 Goldberg (1991) 引入的虚拟字母表和 Radcli e (1991) 定义的局部性形式。 虚拟字母表、局部性格式或区间模式表示搜索空间中的连续区域。 尽管 Eshelman 和 Scha er 设计了一个混合交叉 (BLX) 算子，但他们并没有从区间模式处理的角度构造交叉算子。 在后面的部分中，我们观察到他们找到的最佳交叉 BLX-0.5 并不能完全令人满意地将区间模式从父点传播到子点。 有趣的是，我们发现 SBX 算子的特殊情况比他们报告的最佳 BLX-0.5 算子更好地处理区间模式。

在有关进化策略的文献中，直接使用实值参数，但在这些研究中使用变异作为主要搜索算子（Rechenberg，1973）。 直到最近，交叉算子才被用于进化策略研究（Back、Ho meister 和 Schwefel，1991）。 对于每个变量，离散交叉选择父值之一作为子变量，中间交叉使用父值的平均值作为子变量。 虽然引入了其他类型的交叉算子，但这些算子是确定性的，只能创建一个搜索点。 因此，这些运营商没有足够的搜索能力。 然而，如果考虑交叉和后续变异算子的影响，它们的组合搜索能力就变得很重要。 由于本文主要讨论和比较交叉算子，所以不考虑进化策略方法中交叉算子和变异算子的联合作用。























































































































































































































































































