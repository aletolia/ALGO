# Multi-objective optimization using genetic algorithms: A tutorial

## 1.Introduction

本文的目的是介绍使用遗传算法 (GA) 的多目标优化方法的概述和教程。 对于多目标问题，目标通常是相互冲突的，从而阻止了每个目标的同时优化。 许多甚至大多数实际工程问题实际上都有多个目标，即最小化成本、最大化性能、最大化可靠性等。这些都是困难但现实的问题。  GA 是一种流行的元启发式算法，特别适合此类问题。 传统的遗传算法通过使用专门的适应度函数和引入促进解决方案多样性的方法来定制以适应多目标问题。

多目标优化有两种通用方法。 一种是将单独的目标函数组合成一个单一的复合函数，或者将除一个目标之外的所有目标移动到约束集。 在前一种情况下，可以通过效用理论、加权总和法等方法确定单个目标，但问题在于正确选择权重或效用函数来表征决策者的偏好。

在实践中，即使对于熟悉问题域的人，也很难准确地选择这些权重。 使这个缺点更加复杂的是，需要在目标之间进行缩放，权重的小扰动有时会导致完全不同的解决方案。 在后一种情况下，问题是要将目标移动到约束集，必须为这些先前的每个目标建立一个约束值。

这可能相当随意。 在这两种情况下，优化方法将返回单个解决方案，而不是一组可以进行权衡检查的解决方案。 出于这个原因，考虑到多个目标，决策者通常更喜欢一套好的解决方案。

第二种通用方法是确定整个帕累托最优解集或代表性子集。 帕累托最优集是一组相互之间非支配的解。 在从一种帕累托解决方案转移到另一种帕累托解决方案时，在一个或多个目标中总会有一定的牺牲，以在其他（多个）目标中获得一定的收益。 帕累托最优解集通常比单一解更受青睐，因为它们在考虑现实生活中的问题时很实用，因为决策者的最终解总是一种权衡。 帕累托最优集可以有不同的大小，但帕累托集的大小通常随着目标数量的增加而增加。

## 2.Multi-objective optimization formulation

考虑一个决策者，他希望优化 K 个目标，使得这些目标是不可公度的，并且决策者对彼此之间的目标没有明确的偏好。 不失一般性，所有目标都是最小化类型——最小化类型的目标可以通过乘以负数来转换为最大化类型。 一个具有 $K$​​ 个目标的最小化多目标决策问题定义如下： 给定解空间 $X$​​ 中的一个 $n$​​ 维决策变量向量 $x =\{x_1,...,x_n\} $​​，找到一个向量 $x^*$​ 来最小化给定的一组 $K$​ 目标函数 $z(x^*) = {z_1(x^*),...,z_K(x^*)}$​。 解空间 $X$​ 通常受到一系列约束的限制，例如 $g_j(x^*) =b_j\ for\ j= 1, ..., m$, 以及决策变量的边界。

在现实生活中的许多问题中，所考虑的目标相互冲突。 因此，针对单个目标优化 $x$ 通常会导致针对其他目标的不可接受的结果。 因此，同时优化每个目标函数的完美多目标解决方案几乎是不可能的。 多目标问题的合理解决方案是研究一组解决方案，每个解决方案都在可接受的水平上满足目标，而不受任何其他解决方案的支配。

如果所有目标函数都是为了最小化，则称一个可行解 $x$​​​​ 支配另一个可行解 $y (x >y)$​​​，当且仅当， $z_i(x)\le z_i(y)$​​​ ($i=1,..,K$​​) 以及 $z_j(  x)<z_j(y)$​ 用于至少一个目标函数 $j$​。 如果一个解不受解空间中任何其他解的支配，则称该解是帕累托最优的。 帕累托最优解不能在不恶化至少一个其他目标的情况下针对任何目标进行改进。 $X$​ 中所有可行的非支配解的集合称为帕累托最优集，对于给定的帕累托最优集，目标空间中对应的目标函数值称为帕累托前沿。 对于许多问题，帕累托最优解的数量是巨大的（可能是无限的）。

多目标优化算法的最终目标是确定帕累托最优集中的解。 然而，对于许多多目标问题，识别整个帕累托最优集实际上是不可能的，因为它的大小。 此外，对于许多问题，尤其是组合优化问题，解决方案最优性的证明在计算上是不可行的。 因此，多目标优化的一种实用方法是研究一组尽可能代表帕累托最优集的解决方案（最著名的帕累托集）。 考虑到这些问题，多目标优化方法应该实现以下三个相互矛盾的目标 [1]：

1. 已知最优的帕累托前沿应该尽可能接近真正的帕累托前沿。 理想情况下，最著名的帕累托集应该是帕累托最优集的子集。
  2. 最著名的帕累托集中的解决方案应该在帕累托前沿上均匀分布和多样化，以便为决策者提供权衡的真实画面。
  3. 最著名的帕累托前沿应该捕获帕累托前沿的整个频谱。 这需要在目标函数空间的极端研究解决方案。

对于给定的计算时间限制，第一个目标最好通过将搜索集中（加强）帕累托前沿的特定区域来实现。 相反，第二个目标要求搜索工作在帕累托前沿上均匀分布。 第三个目标旨在扩展两端的帕累托前沿，探索新的极端解决方案。

本文介绍了多目标遗传算法中使用的常用方法，以在解决多目标优化问题的同时实现这三个相互冲突的目标。

## 3.Genetic algorithms

GA 的概念是由 Holland 及其同事在 1960 年代和 1970 年代提出的 [2]。  GA 的灵感来自解释物种起源的进化论。 在自然界中，环境中的弱者和不适合的物种面临着自然选择的灭绝。 强者更有机会通过繁殖将基因传给后代。 从长远来看，基因中携带正确组合的物种在其种群中占据优势。 有时，在缓慢的进化过程中，基因可能会发生随机变化。

如果这些变化在生存挑战中提供了额外的优势，新物种就会从旧物种进化而来。 自然选择消除了不成功的变化。在 GA 术语中，解向量 $x\in X$ 称为个体或染色体。 染色体由称为基因的离散单元组成。 每个基因控制染色体的一个或多个特征。 在 Holland 最初的 GA 实现中，基因被假定为二进制数字。 在后来的实施中，引入了更多不同的基因类型。 通常，染色体对应于解空间中的唯一解 $x$。 这需要解空间和染色体之间的映射机制。 这种映射称为编码。

事实上，GA 致力于解决问题的编码，而不是解决问题本身。遗传算法处理一组染色体，称为种群。 总体通常是随机初始化的。随着搜索的发展，种群包括更合适的解决方案和更合适的解决方案，并最终收敛，这意味着它由单一解决方案主导。  Holland 还提出了收敛性证明（模式定理）到全局最优解，其中染色体是二元向量。

GA 使用两个算子从现有的解决方案中生成新的解决方案：交叉和变异。 交叉算子是遗传算法最重要的算子。 在交叉中，通常称为父母的两条染色体结合在一起形成新的染色体，称为后代。 亲本是从种群中现有的染色体中选择的，优先考虑适合度，从而期望后代继承使亲本更适合的良好基因。 通过迭代应用交叉算子，好的染色体的基因有望在群体中更频繁地出现，最终导致收敛到一个整体好的解决方案

变异算子将随机变化引入到染色体的特征中。 突变通常应用于基因水平。 在典型的 GA 实现中，突变率（改变基因特性的概率）非常小，取决于染色体的长度。 因此，突变产生的新染色体与原来的染色体不会有太大的不同。 突变在遗传算法中起着至关重要的作用。 如前所述，交叉使种群中的染色体相似，从而导致种群收敛。 突变将遗传多样性重新引入种群中，并帮助搜索逃离局部最优。   繁殖涉及为下一代选择染色体。 在最一般的情况下，个体的适应度决定了其为下一代生存的概率。 根据适应度值的使用方式，GA 中有不同的选择程序。   比例选择、排名和锦标赛选择是最流行的选择程序。 通用遗传算法[3]的过程如下：

第 1 步：设置 $t =1$。随机生成 $N$ 个解以形成第一个种群 $P_1$。 评估 $P_1$ 中解的适合度。

第 2 步：交叉：按如下方式生成后代种群 $Q_t$： 

2.1． 根据适应度值从 $P_t$ 中选择两个解 $x$ 和 $y$。

2.2. 使用交叉运算符，生成后代并将它们添加到 $Q_t$。

第 3 步：变异：用预定义的变异率变异每个解 $x\in Q_t$。

第 4 步：适应度分配：根据每个解 $x\in Q_t$ 的目标函数值和不可行性评估并为其分配适应度值。

第五步：选择：根据适合度从 $Q_t$​ 中选择 $N$​ 个解，复制到 $P_{t+1}$。

Step 6：如果满足停止条件，则终止搜索返回当前种群，否则设t ¼ t+1 转Step 2。

## 4.Multi-objective GA

作为一种基于群体的方法，遗传算法非常适合解决多目标优化问题。 可以修改通用的单目标 GA 以在一次运行中找到一组多个非支配解决方案。  GA 同时搜索解空间的不同区域的能力使得为具有非凸、不连续和多模态解空间的难题找到一组不同的解决方案成为可能。  GA 的交叉算子可以利用针对不同目标的良好解的结构，在帕累托前沿的未探索部分创建新的非支配解。 此外，大多数多目标 GA 不需要用户对目标进行优先级排序、缩放或权衡。 因此，遗传算法一直是多目标设计和优化问题最流行的启发式方法。 琼斯等人。  [4] 报告说，90% 的多目标优化方法旨在逼近潜在问题的真实帕累托前沿。 其中大部分使用了元启发式技术，所有元启发式方法中有 70% 基于进化方法

第一个多目标 GA，称为向量评估 GA（或 VEGA），由 Schaffer [5] 提出。 随后，开发了几种多目标进化算法，包括多目标遗传算法（MOGA）[6]、Niched Pareto遗传算法（NPGA）[7]、基于权重的遗传算法（WBGA）[8]、随机加权遗传算法 （RWGA）[9]，非支配排序遗传算法（NSGA）[10]，强度帕累托进化算法（SPEA）[11]，改进的SPEA（SPEA2）[12]，帕累托存档进化策略（PAES）[13]， 基于帕累托包络的选择算法 (PESA) [14]、进化多目标优化中的基于区域的选择 (PESA-II) [15]、快速非支配排序遗传算法 (NSGA-II) [16]、多目标进化算法 (  MEA) [17]、Micro-GA [18]、基于秩密度的遗传算法 (RDGA) [19] 和动态多目标进化算法 (DMOEA) [20]。 请注意，尽管文献中多目标 GA 有许多变体，但这些引用的 GA 是众所周知且可靠的算法，已在许多应用中使用，并且在多项比较研究中测试了它们的性能。

几篇关于进化多目标优化的调查论文 [1,11,21-27] 已经发表。  Coello 在他的网站 [28] 中列出了 2000 多篇参考文献。 通常，多目标遗传算法因其适应度分配程序、精英主义或多样化方法而异。 在表 1 中，给出了众所周知的多目标的重点及其优缺点。 大多数关于多目标进化方法的调查论文都介绍和比较了不同的算法。 本文采用不同的课程，重点关注设计多目标 GA 时的重要问题，并描述了多目标 GA 中用于实现多目标优化中的三个目标的常用技术。  Zitzler 等人的调查论文也采用了这种方法。  [1]。 然而，本文的讨论旨在向没有多目标 GA 背景的研究人员和从业者介绍多目标 GA 的组成部分。 同样重要的是要注意，尽管上面引用的几种最先进的算法存在，但许多将多目标 GA 应用于其问题的研究人员更喜欢通过适应各种多目标 GA 的策略来设计自己的定制算法 . 这一观察结果是引入多目标 GA 组件而不是专注于几种算法的另一个动机。 但是，还提供了一些著名的多目标 GA 的伪代码，以演示如何将这些过程合并到多目标 GA 中。

![image-20210811074643571](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20210811074643571.png)

## 5. Design issues and components of multi-objective GA

### 5.1. Fitness functions

#### 5.1.1. Weighted sum approaches

解决多目标优化问题的经典方法是为每个归一化目标函数 $z_i'(x)$ 分配权重 $w_i$，以便将问题转换为具有标量目标函数的单目标问题，如下所示：
$$
min\ z=w_1z_1'(x)+w_2z_2'(x)+...+w_kz_k'(x)\ ——(1)
$$
其中 $z_ i'(x)$​ 是归一化的目标函数 $z_i(x)$​ 和 $\Sigma w_i = 1$​。这种方法被称为先验方法，因为期望用户提供权重。对于给定的权重向量 $w = \{w_1, w_2,...,w_k\}$​ 使用目标函数 (1) 解决问题会产生一个解决方案，如果需要多个解决方案，则必须使用不同的权重组合多次解决该问题。 这种方法的主要困难是为每次运行选择一个权重向量。 自动化这个过程；  Hajela 和 Lin [8] 在 WBGA-MO 中提出了 WBGA for multi-objective optimization (WBGA-MO)，种群中的每个解 $x_i$​ 在计算中使用不同的权重向量 $w_i = \{w_1, w_2,...,w_k\}$​ 求和的目标函数 (1)。 权重向量 $w_i$ 嵌入在解 $x_i$ 的染色体中。 因此，可以在一次运行中同时搜索多个解决方案。 此外，可以调整权重向量以促进种群的多样性。

其他研究人员 [9,31] 提出了基于多个目标函数的加权和的 MOGA，其中在每一代的选择阶段为每个解决方案 $x_i$ 随机生成归一化的权重向量 $w_i$。这种方法旨在在不使用额外参数的情况下在一次运行中规定多个搜索方向。 使用随机权重的 RWGA 的一般程序如下[31]：

程序 RWGA：

$E$ = 外部存档，用于存储迄今为止在搜索过程中找到的非支配解； 

$n_E$ =每一代中从 E 迁移到 P 中的精英解数量

步骤 1：生成随机种群

步骤 2：通过执行以下步骤为每个解 $x\in P_t$ 分配一个适应度值

步骤 2.1：为每个目标 $k(k=1,...,K)$ 生成一个随机数 $u_k\in[0,1]$。

步骤 2.2：计算每个目标 $k$ 的随机权重为 $w_k=(1/u_k)\Sigma_{i=1}^Ku_i$。

步骤 2.3：计算解的适应度为 $f(x)=\Sigma_{k=1}^Kw_kz_k(x)$。

步骤 3：计算每个解 $x\in P_t$ 的选择概率如下： $p(x) = (f(x)-f^{min})^{-1}\Sigma_{y\in P_t}(f(y)-f^{min})$​ 其中 $f^{min} = min\{f (x)|x \in P_t\}$。

第 4 步：使用第 3 步中计算的选择概率选择父母。对选定的父母对应用交叉以创建 N 个后代。使用预定义的突变率变异后代。 将所有后代复制到 $P_{t+1}$。如有必要，更新 E。

步骤 5：从 $P_{t+1}$ 中随机去除 $n_E$ 个解，并将 E 到 Pt+1 中相同数量的解加入。

Step 6：若不满足停止条件，则设t ¼ t þ 1，转Step 2，否则返回E。

加权和方法的主要优点是简单的实现。 由于在适应度分配中使用单个目标，因此可以使用单个目标 GA 进行最少的修改。 此外，这种方法在计算上是高效的。 这种方法的主要缺点是，当真正的帕累托前沿是非凸的时，并不是所有的帕累托最优解都可以研究。 因此，基于加权和方法的多目标遗传算法难以找到均匀分布在非凸折衷面上的解[1]。

#### 5.1.2. Altering objective functions

如前所述，VEGA [5] 是第一个用于通过一组非支配解来逼近帕累托最优集的遗传算法。 在 VEGA 中，种群 $P_t$​ 被随机分成 $K$​ 个大小相等的子种群；  $P_1，P_2，...，P_K$。 然后，基于目标函数 $z_i$ 为子群 $P_i$ 中的每个解决方案分配一个适应度值。 使用交叉和突变的比例选择从这些亚群中选择解决方案。 以与单个目标 GA 相同的方式对新种群执行交叉和变异。

$N_S$​ = 亚群大小 $(N_S = N/K)$

步骤 1：从随机初始种群 $P_0$​ 开始。 设置 $t = 0$。

步骤 2：如果满足停止条件，则返回 $P_t$。

步骤 3：随机排序种群 $P_t$。

步骤 4：对于每个目标 $k$​，$k = 1,...,K$，执行以下步骤：

步骤 4.1：对于 $i = 1 + (k-1)N_S,  .  .  .  ,kN_S$，将适应度值 $f(x_i) = z_k(x_i)$ 分配给排序种群中的第 $i$ 个解

步骤 4.2：根据步骤 4.1 中分配的适应度值，在排序种群的第 $(1+(k -1)N_S)$​ 个和第 ($kN_S$) 个解之间选择 $N_S$ 个解，以创建子种群 $P_k$​。

步骤 5：合并所有子种群 $P_1,...,P_k$​ 并对合并的种群应用交叉和变异以创建大小为 $N$​ 的 $P_{t+1}$​。设置 $t = t + 1$，转到步骤 2

与 VEGA 类似的方法是仅使用单个目标函数，该目标函数每次在选择阶段随机确定 [32]。 交替目标方法的主要优点是易于实现并且在计算上与单目标 GA 一样有效。 事实上，这种方法是单目标遗传算法的直接扩展，用于解决多目标问题。 目标切换的主要缺点是总体趋向于收敛到在一个目标上更好但在其他目标上差的解决方案。

#### 5.1.3. Pareto-ranking approaches

帕累托排序方法明确地利用帕累托优势的概念来评估适应度或为解决方案分配选择概率。 根据优势规则对种群进行排名，然后根据其在种群中的排名，而不是其实际目标函数值，为每个解决方案分配一个适应度值。 请注意，这里假设所有目标都被最小化。 因此，在以下讨论中，较低的等级对应于更好的解决方案。

第一个帕累托排序技术是由 Goldberg [3] 提出的，如下所示：

步骤 1：设置 $i = 1$​ 和 $TP = P$。

步骤 2：识别 $TP$ 中的非支配解并将它们分配给 $F_i$。

第 3 步：设置 $TP = TPF_i$​。 如果 $TP =\varnothing$ 转到步骤 4，否则设置 $i = i + 1$ 并转到步骤 2。

步骤 4：对于第 t 代的每个解 $x\in P$​​，分配排名  $r_1(x,t)=i$​ 如果 $x\in F_i$。

在上面的过程中，$F_1, F_2,...$ 被称为非支配前沿，$F_1$ 是种群 $P$ 的帕累托前沿。 NSGA [10] 也使用类似于上面给出的算法将种群分类为非支配前沿。 然后使用适应度共享函数为每个前沿分配一个虚拟适应度值，使得分配给 $F_i$ 的最差适应度值优于分配给 $F_{i+1}$ 的最佳适应度值。  NSGA-II [16] 是一种更有效的算法，称为快速非支配排序算法，被开发用于形成非支配前沿。  Fonseca 和 Fleming [6] 使用的排名分配方法与基于非支配前沿的排名略有不同，如下所示：
$$
r_2(x,t)=1+nq(x,t)
$$
其中 $nq(x,t)$ 是在第 $t$ 代支配解 $x$​ 的解的数量。 这种排序方法惩罚位于目标函数空间区域中的解，这些区域由帕累托前沿的人口稠密部分主导（覆盖）。 例如，在图 1b 中，解决方案 $i$ 由解决方案 $c$、$d$ 和 $e$ 主导。 因此，尽管它与仅由单个解支配的解 $f$、$g$ 和 $h$ 处于同一前沿，但它被指定为 4。

SPEA [11] 使用排序程序为目标空间中代表性不足的区域的非支配解决方案分配更好的适应度值。 在 SPEA 中，一个固定大小的外部列表 E 存储了迄今为止在搜索过程中研究过的非支配解。 对于每个解 $y\in E$，强度值定义为

<img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20210811115247703.png" alt="image-20210811115247703" style="zoom:67%;" />

其中 $nq (y, t)$​​​ 是 $y$​​ 在 $P$​​ 中占主导地位的解数。解 $y\in E $​ 的等级 $r(y,t)$ 被指定为 $r_3(y,t)=s(y,t) $;  解 $x\in  P$ 的等级计算为
$$
r_3(x,t)=1+\Sigma_{y\in E,y>x}s(y,t)
$$
图 1c 说明了 SPEA 排名方法的一个例子。 在前两种方法中，所有非支配解都被指定为 1。然而，这种方法比其他非支配解更偏爱解 a（图中），因为它覆盖了目标函数空间中最少的解。 因此，鼓励广泛、均匀分布的非支配解决方案集。累积排名密度策略 [19] 还旨在惩罚由于过度代表而导致的人口冗余。

这种排名方法被给出为

<img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20210811133550923.png" alt="image-20210811133550923" style="zoom: 67%;" />

要计算解 $x$​ 的等级，必须首先计算支配该解的解的等级。图 1d 显示了这种排序方法的一个例子（基于 $r_2$​）。 使用排序方法 $r_4$​，解决方案 $i、l$ 和 $n$ 在同一非支配前沿的排名高于其对应项，因为覆盖它们的权衡表面部分被三个附近的解决方案 $c$、$d$ 和 $e$ 挤满。

尽管本节中描述的一些排序方法可以直接用于为单个解分配适应度值，但它们通常与各种适应度共享技术相结合，以实现多目标优化中的第二个目标，找到多样化且一致的帕累托前沿

### 5.2. Diversity: fitness assignment, fitness sharing, and niching

保持多样化的种群是多目标 GA 中的一个重要考虑因素，以获得在帕累托前沿上均匀分布的解决方案。 如果不采取预防措施，在多目标遗传算法中，种群往往形成相对较少的集群。 这种现象称为遗传漂变，并且已经设计了以下几种方法来防止遗传漂变。

#### 5.2.1. Fitness sharing

适应度共享通过人为地降低人口稠密地区解决方案的适应度来鼓励在帕累托前沿的未探索部分进行搜索。 为了实现这一目标，确定了人口稠密的区域，并使用惩罚方法来惩罚位于这些区域的解决方案。

适应度共享的想法首先由 Goldberg 和 Richardson [33] 在研究多模态函数的多个局部最优值时提出。  Fonseca 和 Fleming [6] 使用这个想法来惩罚具有相同等级的聚类解决方案，如下所示：

步骤 1：计算 0 和 1 之间归一化目标空间中每个解对 x 和 y 之间的欧几里德距离为(3)

<img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20210811133848948.png" alt="image-20210811133848948" style="zoom:50%;" />

其中 $z^{max} _k$​​ 和 $z^{min}_ k$​ 分别是到目前为止在搜索过程中观察到的目标函数 $z_k()$ 的最大值和最小值。

第 2 步：根据这些距离，计算每个解决方案 $x\in P$​ 的利基数量(4)
$$
nc(x,t)=\Sigma_{y\in P,r(y,t)=r(x,t)}max\{\frac{\sigma_{share-dz(x,y)}}{\sigma_{share}},0\}
$$
其中 $\sigma_{share}$ 是利基规模。

Step 3：计算niche count后，对每个解的适应度进行如下调整：
$$
f'(x,t)=\frac{f(x,t)}{nc(x,t)}
$$
在上面的过程中，$\sigma _{share}$ 定义了目标空间中的解决方案的邻域（图 1a）。 同一邻域的解决方案有助于彼此的利基数量。 因此，拥挤邻域中的解决方案将具有更高的利基数量，从而降低选择该解决方案作为父解决方案的可能性。 因此，生态位限制了目标函数空间的一个特定邻域中解决方案的扩散。

另一种选择是使用决策变量空间中两个解 $x$ 和 $y$ 之间的距离，定义为(5)
$$
dx(x,y)=\sqrt{\frac1M\Sigma_{i=1}^M(x_i-y_i)^2}
$$
在计算利基数量时。 等式 (5) 是衡量两个解决方案之间结构差异的指标。 两个解在目标函数空间中可能非常接近，但它们具有非常不同的结构特征。 因此，基于目标函数空间的适应度共享可能会降低决策变量空间的多样性。 然而，Deb 和 Goldberg [34] 报告说，目标函数空间中的适应度共享通常比基于决策变量空间的适应度共享表现更好。

基于利基计数的适合度共享的缺点之一是用户必须选择一个新的参数 $\sigma_{share}$。 为了解决这个问题，Deb 和 Goldberg [34] 以及 Fonseca 和 Fleming [6] 开发了系统方法来估计和动态更新 $\sigma_{share}$​​。生态位的另一个缺点是计算生态位计数的计算工作量。 然而，健身共享的好处通常超过额外计算工作的成本。

Miller 和 Shaw [35] 提出了一种动态利基共享方法来提高计算利基计数的有效性。MOGA [6] 是第一个明确使用基于 Pareto 的排名和 Niching 技术的多目标 GA，以鼓励搜索真正的 Pareto 前沿，同时保持种群的多样性。

因此，这是一个很好的例子来演示如何将基于帕累托的排序和适应度共享集成到多目标 GA 中。  MOGA 的程序如下：

Procedure MOGA:

步骤 1：从随机初始种群 $P_0$​ 开始。 设置 $t = 0$。

步骤 2：如果满足停止条件，则返回 $P_t$。

步骤 3：按如下方式评估总体的适应度： 

步骤 3.1：使用等式(2)中给出的排名方案为每个解 $x\in P_t$ 分配排名 $r(x,t)$。  (2).
步骤 3.2：根据解决方案的等级为每个解决方案分配适应度值，如下 [36]：
$$
f(x,t)=N-\Sigma_{k=1}^{r(x,t)-1}n_k-.5\times (n_{r(x,t)}-1)
$$
步骤3.3：计算生态位计数 $nc(x,t)$​​；使用公式（4）计算每个解 $x\in P_t$​ 的。
步骤3.4：计算每个 解 $x\in P_t$ 的共享适应度值，如下所示：
$$
f'(x,t)=f(x,t)/nc(x,t)
$$
步骤3.5：通过使用共享的适应度值来规范化适应度值 
$$
f''(x,t)=\frac{f'(x,t)n_{n(x,t)}}{\Sigma_{{y\in P_t}}f'(x,t)}f(x,t)
$$
步骤4：使用基于 $f ''$​ 的随机选择方法为交配池选择亲本。在交配池上应用交叉和变异，直到大小为 $N$​ 的后代群体 $Q_t$​ 填满。设置 $P_{t+1}=Q_t$。

步骤5：设 $t=t+1$，转至步骤2。

在SPEA2[12]中，密度度量用于区分具有相同等级的解，其中解的密度定义为到目标函数空间中第 $k$ 个最近邻居的距离的倒数。解的密度与其生态位计数相似。但是，为参数 $k$ 选择一个值比为 $\sigma_{share}$ 选择一个值更简单。

#### 5.2.2. Crowding distance

拥挤距离方法的目的是在不使用适应度共享参数的情况下，沿着已知最优的帕累托前沿获得解的均匀分布。例如，NSGA-II[16]使用拥挤距离法，如下所示（图2b）：

步骤1：对种群进行排序，并确定非支配锋 $F_1、F_2、...、F_R$。对于每个锋 $j =1、...、R$，重复步骤2和3。

步骤2：对于每个目标函数 $k$​​​，按升序对 $F_j$​​​ 中的解进行排序。设 $l= |F_j|$​​ 和 $x_{\{i,k\}}$ ​ 表示排序列表中关于目标函数 $k$ 的第 $i$ 个解。分配cdkðx½1；k222;¼1和cdkðx½l；kÞ¼1，对于i¼2，y，l1赋值

































































































































































































































































































































































































